
<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Bi-LSTM 实践 | Yu~Cheng Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="标签（空格分隔）： 神经网络 NER 

模型基础1. RNN基本概念：

batch_size : SGD迭代参数使用的样本量
模型启动
123456789101112131415161718with tf.Session() as sess:    sess.run(init)    step = 1    while step * batch_size &amp;lt; training_iters">
<meta property="og:type" content="article">
<meta property="og:title" content="Bi-LSTM 实践">
<meta property="og:url" content="http://yoursite.com/2016/09/30/NLP/Bi-LSTM 实践/index.html">
<meta property="og:site_name" content="Yu~Cheng Blog">
<meta property="og:description" content="标签（空格分隔）： 神经网络 NER 

模型基础1. RNN基本概念：

batch_size : SGD迭代参数使用的样本量
模型启动
123456789101112131415161718with tf.Session() as sess:    sess.run(init)    step = 1    while step * batch_size &amp;lt; training_iters">
<meta property="og:updated_time" content="2016-09-30T03:43:27.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bi-LSTM 实践">
<meta name="twitter:description" content="标签（空格分隔）： 神经网络 NER 

模型基础1. RNN基本概念：

batch_size : SGD迭代参数使用的样本量
模型启动
123456789101112131415161718with tf.Session() as sess:    sess.run(init)    step = 1    while step * batch_size &amp;lt; training_iters">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css">
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
</head>
<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Yu~Cheng Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">AboutMe</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" class="search-form">
          <input type="search" name="word" maxlength="20" class="search-form-input" placeholder="Search">
          <input type="submit" value="" class="search-form-submit">
          <input name=tn type=hidden value="bds">
          <input name=cl type=hidden value="3">
          <input name=ct type=hidden value="2097152">
          <input type="hidden" name="si" value="yoursite.com">
        </form>
      </div>
    </div>
  </div>
</header>
    <div class="outer">
      <section id="main"><article id="post-NLP/Bi-LSTM 实践" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2016/09/30/NLP/Bi-LSTM 实践/" class="article-date">
  <time datetime="2016-09-30T02:03:23.000Z" itemprop="datePublished">2016-09-30</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/NLP/">NLP</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Bi-LSTM 实践
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>标签（空格分隔）： 神经网络 NER </p>
<hr>
<h2 id="模型基础"><a href="#模型基础" class="headerlink" title="模型基础"></a>模型基础</h2><h3 id="1-RNN"><a href="#1-RNN" class="headerlink" title="1. RNN"></a>1. RNN</h3><p>基本概念：</p>
<ul>
<li>batch_size : SGD迭代参数使用的样本量</li>
<li><p>模型启动</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    step = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> step * batch_size &lt; training_iters:</span><br><span class="line">        <span class="comment"># 得到训练批次</span></span><br><span class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line">        <span class="comment"># Reshape 到统一维度</span></span><br><span class="line">        <span class="string">''' </span><br><span class="line">            batch_size -- SGD 参数迭代样本量</span><br><span class="line">            n_steps    -- RNN 序列长度</span><br><span class="line">            n_inputs   -- 特征维度</span><br><span class="line">        '''</span></span><br><span class="line">        batch_x = batch_x.reshape((batch_size, n_steps, n_input))</span><br><span class="line">        <span class="comment"># Run optimization op (backprop)</span></span><br><span class="line">        sess.run(optimizer, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">        acc = sess.run(accuracy, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">        loss = sess.run(cost, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">        step += <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>accuracy 计算</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pred = BiRNN(x, weights, biases) <span class="comment"># BiRNN 计算结果</span></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))</span><br><span class="line"><span class="comment"># minimize 损失函数</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line"><span class="comment"># Evaluate model</span></span><br><span class="line">correct_pred = tf.equal(tf.argmax(pred,<span class="number">1</span>), tf.argmax(y,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br></pre></td></tr></table></figure>
<ul>
<li><p>最简单的 RNN 神经网络形式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">state = cell.zero_state(...)</span><br><span class="line">outputs = []</span><br><span class="line"><span class="keyword">for</span> input_ <span class="keyword">in</span> inputs:</span><br><span class="line">    output, state = cell(input_, state)</span><br><span class="line">    outputs.append(output)</span><br><span class="line"><span class="keyword">return</span> (outputs, state)</span><br></pre></td></tr></table></figure>
</li>
<li><p>BiRNN 函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BiRNN</span><span class="params">(x, weights, biases)</span>:</span></span><br><span class="line">    <span class="comment">## 转置</span></span><br><span class="line">    x = tf.transpose(x, [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">    <span class="comment"># Reshape 成 2D 矩阵 (n_steps * batch_size, n_input)</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">-1</span>, n_input])</span><br><span class="line">    <span class="comment"># Split 分割成 n_steps 的 tensors 数组 (batch_size, n_input)</span></span><br><span class="line">    x = tf.split(<span class="number">0</span>, n_steps, x)</span><br><span class="line">    <span class="comment"># Forward direction cell</span></span><br><span class="line">    lstm_fw_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=<span class="number">1.0</span>)</span><br><span class="line">    <span class="comment"># Backward direction cell</span></span><br><span class="line">    lstm_bw_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=<span class="number">1.0</span>)</span><br><span class="line">    <span class="comment"># Get lstm cell output</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        outputs, _, _ = rnn.bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,dtype=tf.float32)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        outputs = rnn.bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,dtype=tf.float32)</span><br><span class="line">    <span class="comment"># Linear activation, using rnn inner loop last output, 概率返回</span></span><br><span class="line">    <span class="keyword">return</span> tf.matmul(outputs[<span class="number">-1</span>], weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br></pre></td></tr></table></figure>
</li>
</ul>

      
    </div>
    <footer class="article-footer">
      
        <a data-url="http://yoursite.com/2016/09/30/NLP/Bi-LSTM 实践/" data-id="citp8l4nm0007uo0d4o3xpuwu" class="article-share-link" data-share="baidu" data-title="Bi-LSTM 实践">分享到</a>
      

      
        <a href="http://yoursite.com/2016/09/30/NLP/Bi-LSTM 实践/#ds-thread" class="article-comment-link">评论</a>
      

      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/09/30/NLP/关系挖掘/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">关系挖掘</div>
    </a>
  
</nav>

  
</article>


  <section id="comments">
    <div id="ds-thread" class="ds-thread" data-thread-key="2016/09/30/NLP/Bi-LSTM 实践/" data-title="Bi-LSTM 实践" data-url="http://yoursite.com/2016/09/30/NLP/Bi-LSTM 实践/"></div>
  </section>
</section>
      
      <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">分类</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/NLP/">NLP</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/充电/">充电</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/WSD/">WSD</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/关系/">关系</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/机器学习/">机器学习</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/神经网络/">神经网络</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/WSD/" style="font-size: 10px;">WSD</a> <a href="/tags/关系/" style="font-size: 10px;">关系</a> <a href="/tags/机器学习/" style="font-size: 10px;">机器学习</a> <a href="/tags/神经网络/" style="font-size: 10px;">神经网络</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">九月 2016</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">八月 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">七月 2016</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">近期文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2016/09/30/NLP/Bi-LSTM 实践/">Bi-LSTM 实践</a>
          </li>
        
          <li>
            <a href="/2016/09/30/NLP/关系挖掘/">关系挖掘</a>
          </li>
        
          <li>
            <a href="/2016/09/30/NLP/命名实体消歧/">命名实体消歧</a>
          </li>
        
          <li>
            <a href="/2016/08/30/machine-learning/">机器学习基本概念</a>
          </li>
        
          <li>
            <a href="/2016/07/30/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">友情链接</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="https://github.com/machineIceGit" target="_blank">my github</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2016 John Doe<br>
      Powered by <a href="//hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/xiangming/landscape-plus" target="_blank">Landscape-plus</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">AboutMe</a>
  
</nav>
  <!-- totop start -->
<div id="totop">
<a title="返回顶部"><img src="/img/scrollup.png"/></a>
</div>

<!-- totop end -->

<!-- 多说公共js代码 start -->
<script type="text/javascript">
var duoshuoQuery = {short_name:"reqianduan"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0]
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- 多说公共js代码 end -->


<!-- 百度分享 start -->

<div id="article-share-box" class="article-share-box">
  <div id="bdshare" class="bdsharebuttonbox article-share-links">
    <a class="article-share-weibo" data-cmd="tsina" title="分享到新浪微博"></a>
    <a class="article-share-weixin" data-cmd="weixin" title="分享到微信"></a>
    <a class="article-share-qq" data-cmd="sqq" title="分享到QQ"></a>
    <a class="article-share-renren" data-cmd="renren" title="分享到人人网"></a>
    <a class="article-share-more" data-cmd="more" title="更多"></a>
  </div>
</div>
<script>
  function SetShareData(cmd, config) {
    if (shareDataTitle && shareDataUrl) {
      config.bdText = shareDataTitle;
      config.bdUrl = shareDataUrl;
    }
    return config;
  }
  window._bd_share_config={
    "common":{onBeforeClick: SetShareData},
    "share":{"bdCustomStyle":"/css/bdshare.css"}
  };
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

<!-- 百度分享 end -->

<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>




<! -- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
                processEscapes: true
                    
}
  
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
                  
}
    
        });
</script>

<script type="text/x-mathjax-config">
MathJax.Hub.Queue(function() {
            var all = MathJax.Hub.getAllJax(), i;
            for(i=0; i < all.length; i += 1) {
                            all[i].SourceElement().parentNode.className += ' has-jax';
                                    
            }
                
        });
</script>

<script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<script src="/js/script.js"></script>

</div>
</body>
</html>
