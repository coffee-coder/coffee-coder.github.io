<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="Yu~Cheng Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Yu~Cheng Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Yu~Cheng Blog">
<meta name="twitter:description">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://yoursite.com/"/>

  <title> Yu~Cheng Blog </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Yu~Cheng Blog</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/17/database-invest/" itemprop="url">
                  Database Invest
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-17T17:03:53+08:00" content="2017-04-17">
              2017-04-17
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Relation-vs-Document"><a href="#Relation-vs-Document" class="headerlink" title="Relation vs Document"></a>Relation vs Document</h3><p>Relational databases generally store data in separate tables that are defined by the programmer, and a single object may be spread across several tables. Document databases store all information for a given object in a single instance in the database,and every stored object can be different from every other.</p>
<p>For example, the following is a document, encoded in JSON:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"FirstName"</span>: <span class="string">"Bob"</span>, </span><br><span class="line">    <span class="attr">"Address"</span>: <span class="string">"5 Oak St."</span>, </span><br><span class="line">    <span class="attr">"Hobby"</span>: <span class="string">"sailing"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>encoded in XML</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">contact</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">firstname</span>&gt;</span>Bob<span class="tag">&lt;/<span class="name">firstname</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">lastname</span>&gt;</span>Smith<span class="tag">&lt;/<span class="name">lastname</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">phone</span> <span class="attr">type</span>=<span class="string">"Cell"</span>&gt;</span>(123) 555-0178<span class="tag">&lt;/<span class="name">phone</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">phone</span> <span class="attr">type</span>=<span class="string">"Work"</span>&gt;</span>(890) 555-0133<span class="tag">&lt;/<span class="name">phone</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">address</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">type</span>&gt;</span>Home<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">street1</span>&gt;</span>123 Back St.<span class="tag">&lt;/<span class="name">street1</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">city</span>&gt;</span>Boys<span class="tag">&lt;/<span class="name">city</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">state</span>&gt;</span>AR<span class="tag">&lt;/<span class="name">state</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">zip</span>&gt;</span>32225<span class="tag">&lt;/<span class="name">zip</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">country</span>&gt;</span>US<span class="tag">&lt;/<span class="name">country</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">address</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">contact</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>Keys</p>
<ul>
<li>This key is a simple identifier (or ID), typically a string, a URI, or a path</li>
<li>The key can be used to retrieve the document from the database. </li>
<li>Typically the database retains an index on the key to speed up document retrieval, and in some cases the key is required to create or insert the document into the database.</li>
</ul>
<p>Retrieval</p>
<ol>
<li>Simple key-to-document lookup that can be used to retrieve a document</li>
<li>API or query language that allows the user to retrieve documents based on content (or metadata)</li>
<li>Document stores use the metadata in the document to classify the content, allowing them, for instance, to understand that one series of digits is a phone number, and another is a postal code. This allows them to search on those types of data, for instance, all phone numbers containing 555, which would ignore the zip code 55555.</li>
</ol>
<p>Relations</p>
<ol>
<li>A document-oriented database is a specialized <strong>key-value</strong> store, which itself is another NoSQL database category.</li>
<li>In a simple key-value store, the document content is opaque. A document-oriented database provides APIs or a query/update language that exposes the ability to query or update based on the internal structure in the document. </li>
<li>In a relational database, data is first categorized into a number of predefined types, and tables are created to hold individual entries, or records, of each type. </li>
<li>A key concept in the relational design is that any data that may be repeated is normally placed in its own table, and if these instances are related to each other, a column is selected to group them together, the foreign key. This design is known as database normalization.</li>
<li>A key difference between the document-oriented and relational models is that the data formats are not predefined in the document case.</li>
</ol>
<h3 id="Graph-vs-Document"><a href="#Graph-vs-Document" class="headerlink" title="Graph vs Document"></a>Graph vs Document</h3><p>Graph databases are based on graph theory, and employ nodes, edges, and properties.</p>
<ol>
<li>That is, having selected a user, the pointer can be followed directly to the email records, there is no need to search the email table to find the matching records. </li>
<li>For example, if one searches for all of the email addresses for users in area code “311”, the engine would first perform a conventional search to find the users in “311”, but then retrieve the email addresses by following the links found in those records. <ul>
<li>A relational database would first find all the users in “311”, extract a list of the pk’s, perform another search for any records in the email table with those pk’s, and link the matching records together. </li>
</ul>
</li>
<li>graph vs document<img src="/2017/04/17/database-invest/MongoDB.png" alt="MongoDB" title="MongoDB">
<img src="/2017/04/17/database-invest/OrientDB.png" alt="OrientDB" title="OrientDB">
</li>
</ol>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ol>
<li>relation vs document : key-value</li>
<li>relation vs graph : kkv</li>
<li>document vs  graph ： kkv - kv</li>
</ol>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul>
<li><a href="http://orientdb.com/orientdb-vs-mongodb/" target="_blank" rel="external">http://orientdb.com/orientdb-vs-mongodb/</a></li>
<li><a href="http://www.oschina.net/news/63333/performance-comparison-between-arangodb" target="_blank" rel="external">http://www.oschina.net/news/63333/performance-comparison-between-arangodb</a></li>
<li><a href="https://en.wikipedia.org/wiki/Document-oriented_database" target="_blank" rel="external">https://en.wikipedia.org/wiki/Document-oriented_database</a></li>
<li><a href="https://en.wikipedia.org/wiki/Graph_database" target="_blank" rel="external">https://en.wikipedia.org/wiki/Graph_database</a><br><a href="https://en.wikipedia.org/wiki/ACID#Atomicity_failure" target="_blank" rel="external">https://en.wikipedia.org/wiki/ACID#Atomicity_failure</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/04/14/NLP/NLG综述/" itemprop="url">
                  NLG综述
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-04-14T16:56:56+08:00" content="2017-04-14">
              2017-04-14
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>标签 ： seq2seq NLG </p>
<hr>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>   <em>Natural language generation</em> ( NLG ) is the natural language processing task of generating natural language from a machine representation system such as a knowledge base or a logical form.(From wikipedia) , NLG 可以看作是 NLU (自然语言理解)的反向过程，在 <em>NLU</em> 中，系统需要将输入的自然语句转换成机器表示形式，而 NLG 则是将考虑如何将概念转换成语言。<br><img src="/2017/04/14/NLP/NLG综述/figure01.png" alt="figure01" title="figure01"><br><img src="/2017/04/14/NLP/NLG综述/figure02.png" alt="figure02" title="figure02"></p>
<h2 id="相关工作"><a href="#相关工作" class="headerlink" title="相关工作"></a>相关工作</h2><ol>
<li><p><strong>传统方法</strong></p>
<ul>
<li><p>模版生成，如天气预报</p>
<figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TempString = <span class="keyword">case</span> (TEMP - AVERAGETEMP)</span><br><span class="line">    <span class="meta">[</span><span class="number">2.0</span> <span class="attr">...</span> <span class="number">2.9</span><span class="meta">]</span>:      比平均温度高非常多。</span><br><span class="line">    <span class="meta">[</span><span class="number">1.0</span> <span class="attr">...</span> <span class="number">1.9</span><span class="meta">]</span>:      比平均温度高很多。</span><br><span class="line">    <span class="meta">[</span><span class="number">0.1</span> <span class="attr">...</span> <span class="number">0.9</span><span class="meta">]</span>:      比平均温度高一点。</span><br><span class="line">    <span class="meta">[</span><span class="number">-0.1</span> <span class="attr">...</span> <span class="number">-0.9</span><span class="meta">]</span>:    比平均温度低一点。</span><br><span class="line">    <span class="meta">[</span><span class="number">-1.0</span> <span class="attr">...</span> <span class="number">-1.9</span><span class="meta">]</span>:    比平均温度低很多。</span><br><span class="line">    <span class="meta">[</span><span class="number">-2.0</span> <span class="attr">...</span> <span class="number">-2.9</span><span class="meta">]</span>:    比平均温度低非常多。</span><br></pre></td></tr></table></figure>
<p>这些结果都是逐句生成的，准确但是很呆板，我们希望看到的是更自然的表达，因此需要做句子规划。</p>
</li>
<li>sentence planning<ul>
<li>Lexicalisation：选择词和短语来表达概念和关系。</li>
<li>Aggregation: 把词和短语进行组合。</li>
<li>Referring expression generation：指称表达生成。<img src="/2017/04/14/NLP/NLG综述/figure05.png" alt="figure05" title="figure05"></li>
</ul>
</li>
<li>这三个任务都是独立的，并且是非常困难的<ul>
<li>Lexical choice ：非常多的选择，比如 “晚饭”，“晚餐”</li>
<li>Aggregation:是一个词还是多个词？</li>
<li>Referring expression generation：“这本书”，“一本书”，“他写的书”</li>
</ul>
</li>
<li>随着深度学习的流行，依赖人工设定的特征可以交给模型去生成。</li>
</ul>
</li>
<li><strong>GNMT</strong><ul>
<li>seq2seq 的典型应用是机器翻译，由于翻译过程中讲究”信达雅”,”信”的过程需要对齐，因此在基础的 encoder-decoder 框架上加入 attention 机制，保证 decoder 的词能够和 encoder 输入的词对齐。  <img src="/2017/04/14/NLP/NLG综述/figure04.png" alt="figure04" title="figure04"></li>
<li>模型<ul>
<li>模型比较简单:<ul>
<li>encoder : x1, x2, …, xM = EncoderRNN(x1, x2, x3, …, xM)</li>
<li>decoder : P(Y |X) = P(Y |x1, x2, x3, …, xM)</li>
<li>attention :   <img src="/2017/04/14/NLP/NLG综述/figure08.png" alt="figure08" title="figure08">
  就是原先只有 encoder 的最后一个状态输出，现在是一个加权平均，参数主要是在 AttentionFunction , AF 可以是一个线形函数，也可以是非线性神经网络，在 GNMT 中是包含一个隐含层的前向网络。</li>
</ul>
</li>
<li>整体的Framework，采用了 8 层 deep stacked lstm，encoder 的底层是 双向 LSTM ，剩余层是单向 LSTM, GPU 多就是任性 。<img src="/2017/04/14/NLP/NLG综述/figure06.png" alt="figure06" title="figure06"></li>
<li>优化点<ol>
<li>Quantizable Model and Quantized Inference ：将原先用于 CNN 的模型压缩和训练加速的策略引进到深层 lstm 网络中。</li>
<li>decoder 阶段采用 beam search</li>
</ol>
</li>
<li>Metrics : BLEU</li>
</ul>
</li>
<li>开源代码<ol>
<li><a href="https://github.com/google/seq2seq" target="_blank" rel="external">https://github.com/google/seq2seq</a></li>
</ol>
</li>
<li>总结：大数据、深层网络、多GPU并行、就是干!</li>
</ul>
</li>
<li>ACL 2016 基于模版抽取的 NLG 论文 《<em>Towards Constructing Sports News from Live Text Commentary</em>》，针对赛事直播的新闻生成，难度远高于上文提到的任务。 <ul>
<li>作者一开始也是将直播任务看作是文本摘要的任务，希望从现有文本中抽取信息来生成新闻，文本来源多数是解说的解说词，解说词有很多明显的特点：时序性，短文本，局部冗余。这些特点会导致简单通过文本摘要的方式来抽取特征比较困难。</li>
<li>面临上述的问题，作者提出以下解决方案：<ul>
<li>将任务建模为 learning to rank framework，将传统的文本摘要特征和任务特定特征抽取相互结合。</li>
<li>提出基于概率的句子选择算法来解决语料的局部冗余问题。</li>
</ul>
</li>
<li>建模过程<ul>
<li>将一场赛事的解说稿看成一个文档集合 {s1, s2, …, sn }，我们需要从中抽取出一些句子来对这场比赛进行总结。句子的数量定长为 B 。</li>
</ul>
</li>
<li>句子表示<ul>
<li>basic feature: 比较细节，参见文章</li>
</ul>
</li>
<li>句子选择<ul>
<li>采用 LTR 模型。</li>
</ul>
</li>
<li>一句话总结，就是利用 LTR 从解说稿中选取分数最高的句子，然后把这些句子原封不动的重新组合，他强任他强，清风拂云岗。</li>
</ul>
</li>
<li>《Generating Text with Deep Reinforcement Learning》强化学习在 decoder 阶段的应用，训练 DQN 模型进行解码。 <img src="/2017/04/14/NLP/NLG综述/figure09.png" alt="figure09" title="figure09">
<ul>
<li>语言模型本身就是马尔可夫过程的离散形式，称之为马尔可夫链。同时在 GNMT 优化 decoder 中使用的 beam search 是一种动态规划算法，目标是最小化 score function s(Y,X)，如果不做长度正则化的话，结果会偏向于生成短文本。</li>
<li>在 DQN 中 Bellman equation 近似 beam search 的作用。<img src="/2017/04/14/NLP/NLG综述/figure10.png" alt="figure10" title="figure10"></li>
<li>Reword 则为 BLEU Score。</li>
<li>具体算法<img src="/2017/04/14/NLP/NLG综述/figure11.png" alt="figure11" title="figure11"></li>
<li>总结：利用强化学习 decoder 是一个非常不错的应用，直接利用 rnn 生成文本，本质上就是最大化生成序列的联合概率，在样本量少的情况下，会收敛于生成一些”保守词”，另外一个问题是评估过程和训练过程并不是 end-to-end 的，所以没有办法进行干预。引入强化学习相当于是端到端的训练，直接将 BLEU 作为 reward，在模型训练的过程中直接优化最终的效果。</li>
</ul>
</li>
</ol>
<h2 id="评估方式"><a href="#评估方式" class="headerlink" title="评估方式"></a>评估方式</h2><p>评估方式是 NLG 任务比较重要的部分，因此单独介绍，主要针对机器翻译的评估方式。<br>在机器翻译中，依赖参考译文的评价，参考译文就是标准答案，和参考译文越相似，译文质量越高，这个假设是评价算法的基本思想。根据这个指导思想，可以往下有更多的细分，比如从词汇层面和篇章层面，是非语言还是轻语言，或者是重语言的等等，大多数用的都是非语言的评价方法。</p>
<h3 id="非语言"><a href="#非语言" class="headerlink" title="非语言"></a><strong>非语言</strong></h3><ul>
<li><p>基于准确率的评价方法 BLEU<br>BLEU( bilingual evaluation understudy) 的基本假设是：如果待评译文和参考译文的共现 n-grams 越多，译文质量越高。计算公式：</p>
<img src="/2017/04/14/NLP/NLG综述/figure07.png" alt="figure07" title="figure07">
<p>  BP是长度小于参考值的惩罚因子，Pn 是 n-gram 的匹配率。</p>
<ul>
<li>缺点也很明显，评估方式比较机械，而且 n-gram 的稀疏性 没法解决。</li>
<li>改进：MBLEU , EBLEU, AMBER 等。</li>
</ul>
</li>
<li><p>基于召回率的评价方法 ROUGE<br>  a. ROUGE-N:基于 n-gram 的共现统计。<br>  b. ROUGE-L:基于 LCS 的共现统计。<br>  c. ROUGE-W:加权 LCS 的共现统计。<br>  d. ROUGE-S:基于 skip-bigram 的共现统计。<br>  e. ROUGE-SU:基于 skip-bigram 加上 unigram-based 的共现统计。</p>
</li>
</ul>
<h3 id="轻语言"><a href="#轻语言" class="headerlink" title="轻语言"></a><strong>轻语言</strong></h3><p>需要利用一些语言信息进行评价，如词性，同义辞典等，著名的算法有 :<br>    METEOR, METEOR-NEXT, TEP-Plus, MaxSim, wpBLE, TESLA, AMBER 等。</p>
<h3 id="重语言"><a href="#重语言" class="headerlink" title="重语言"></a><strong>重语言</strong></h3><p>则需要对译文进行更多的语法或语意层面的分析，从句法结构，重述，近义，文本蕴含等语言方面评估候选译文和标准译文的相似度，比较著名的算法有 :<br>    ULC, RTE, DCU-LFG<br>缺点是需要对译文做深度的分析和处理，评价的成本比较高，而且处理流程的准确率也会对最终结果有间接影响。</p>
<p>Reference</p>
<ol>
<li>Towards Constructing Sports News from Live Text Commentary</li>
<li>Google’s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</li>
<li>Generating Text with Deep Reinforcement Learning</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/06/tensor-flow-01/" itemprop="url">
                  tensor-flow-01
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-06T16:42:40+08:00" content="2016-10-06">
              2016-10-06
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/学习笔记/" itemprop="url" rel="index">
                    <span itemprop="name">学习笔记</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Tensor-Flow-学习笔记"><a href="#Tensor-Flow-学习笔记" class="headerlink" title="Tensor-Flow 学习笔记"></a>Tensor-Flow 学习笔记</h1><h2 id="tensor-flow-原理"><a href="#tensor-flow-原理" class="headerlink" title="tensor-flow 原理"></a>tensor-flow 原理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure>
<ul>
<li>启动TensorFlow流程，开始管理各种状态，它有一个隐式的默认的图，可以使用 tf.get_default_graph()。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>graph = tf.get_default_graph()</span><br></pre></td></tr></table></figure>
<ul>
<li>TensorFlow图的节点称为 “operation操作” 或者 “ops” ,我们可以使用 graph.get_operations() 看到图中的操作是什么.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>graph.get_default_graph()</span><br></pre></td></tr></table></figure>
<ul>
<li>开始一个简单的计算流</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>m_value = tf.constant(<span class="number">2.0</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>operations = graph.get_operations()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>operations</span><br><span class="line"><span class="comment">## [&lt;tensorflow.python.framework.ops.Operation at 0x1185005d0&gt;] </span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>operations[<span class="number">0</span>].node_def</span><br></pre></td></tr></table></figure>
<ul>
<li>Python 变量 m_value 作为一个节点存在， 同时也是图中的一个操作。</li>
<li>我们对 operations 的操作也验证了这一点， TensorFlow 内部使用 protocol buffer 存储数据，是一种类似 Json 的格式，打印出 node_def 可以看到第一个 protocol buffer.</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/30/NLP/Bi-LSTM 实践/" itemprop="url">
                  Bi-LSTM 实践
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-30T10:03:23+08:00" content="2016-09-30">
              2016-09-30
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/NLP/" itemprop="url" rel="index">
                    <span itemprop="name">NLP</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>标签 ： 神经网络 NER </p>
<hr>
<h2 id="模型基础"><a href="#模型基础" class="headerlink" title="模型基础"></a>模型基础</h2><h3 id="1-RNN"><a href="#1-RNN" class="headerlink" title="1. RNN"></a>1. RNN</h3><p>基本概念：</p>
<ul>
<li>batch_size : SGD迭代参数使用的样本量</li>
<li><p>模型启动</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    step = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> step * batch_size &lt; training_iters:</span><br><span class="line">        <span class="comment"># 得到训练批次</span></span><br><span class="line">        batch_x, batch_y = mnist.train.next_batch(batch_size)</span><br><span class="line">        <span class="comment"># Reshape 到统一维度</span></span><br><span class="line">        <span class="string">''' </span><br><span class="line">            batch_size -- SGD 参数迭代样本量</span><br><span class="line">            n_steps    -- RNN 序列长度</span><br><span class="line">            n_inputs   -- 特征维度</span><br><span class="line">        '''</span></span><br><span class="line">        batch_x = batch_x.reshape((batch_size, n_steps, n_input))</span><br><span class="line">        <span class="comment"># Run optimization op (backprop)</span></span><br><span class="line">        sess.run(optimizer, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">        acc = sess.run(accuracy, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">        loss = sess.run(cost, feed_dict=&#123;x: batch_x, y: batch_y&#125;)</span><br><span class="line">        step += <span class="number">1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>accuracy 计算</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pred = BiRNN(x, weights, biases) <span class="comment"># BiRNN 计算结果</span></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))</span><br><span class="line"><span class="comment"># minimize 损失函数</span></span><br><span class="line">optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)</span><br><span class="line"><span class="comment"># Evaluate model</span></span><br><span class="line">correct_pred = tf.equal(tf.argmax(pred,<span class="number">1</span>), tf.argmax(y,<span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br></pre></td></tr></table></figure>
</li>
<li><p>最简单的 RNN 神经网络形式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">state = cell.zero_state(...)</span><br><span class="line">outputs = []</span><br><span class="line"><span class="keyword">for</span> input_ <span class="keyword">in</span> inputs:</span><br><span class="line">    output, state = cell(input_, state)</span><br><span class="line">    outputs.append(output)</span><br><span class="line"><span class="keyword">return</span> (outputs, state)</span><br></pre></td></tr></table></figure>
</li>
<li><p>BiRNN 函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">BiRNN</span><span class="params">(x, weights, biases)</span>:</span></span><br><span class="line">    <span class="comment">## 转置</span></span><br><span class="line">    x = tf.transpose(x, [<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line">    <span class="comment"># Reshape 成 2D 矩阵 (n_steps * batch_size, n_input)</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">-1</span>, n_input])</span><br><span class="line">    <span class="comment"># Split 分割成 n_steps 的 tensors 数组 (batch_size, n_input)</span></span><br><span class="line">    x = tf.split(<span class="number">0</span>, n_steps, x)</span><br><span class="line">    <span class="comment"># Forward direction cell</span></span><br><span class="line">    lstm_fw_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=<span class="number">1.0</span>)</span><br><span class="line">    <span class="comment"># Backward direction cell</span></span><br><span class="line">    lstm_bw_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=<span class="number">1.0</span>)</span><br><span class="line">    <span class="comment"># Get lstm cell output</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        outputs, _, _ = rnn.bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,dtype=tf.float32)</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        outputs = rnn.bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,dtype=tf.float32)</span><br><span class="line">    <span class="comment"># Linear activation, using rnn inner loop last output, 概率返回</span></span><br><span class="line">    <span class="keyword">return</span> tf.matmul(outputs[<span class="number">-1</span>], weights[<span class="string">'out'</span>]) + biases[<span class="string">'out'</span>]</span><br></pre></td></tr></table></figure>
</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/08/30/machine-learning/" itemprop="url">
                  机器学习基本概念
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-08-30T02:03:23+08:00" content="2016-08-30">
              2016-08-30
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/充电/" itemprop="url" rel="index">
                    <span itemprop="name">充电</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="生成式模型"><a href="#生成式模型" class="headerlink" title="生成式模型"></a>生成式模型</h2><ol>
<li>贝叶斯模型.</li>
<li>HMM.</li>
</ol>
<h2 id="判别式模型"><a href="#判别式模型" class="headerlink" title="判别式模型"></a>判别式模型</h2><ol>
<li>CRF</li>
</ol>
<h2 id="学习步骤"><a href="#学习步骤" class="headerlink" title="学习步骤"></a>学习步骤</h2><p>机器学习是一个以参数学习为目标的数学方式</p>
<ol>
<li>模型表示<br> logistics</li>
<li>误差函数<br> 最大熵，sigmod</li>
<li>目标函数<br> 最小二乘、最大似然、MAP</li>
<li>优化策略<br> 梯度下降、坐标下降</li>
</ol>
<h2 id="参数学习"><a href="#参数学习" class="headerlink" title="参数学习"></a>参数学习</h2><ol>
<li>EM算法</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/07/30/hello-world/" itemprop="url">
                  Hello World
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-07-30T02:03:23+08:00" content="2016-07-30">
              2016-07-30
            </time>
          </span>

          

          
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  


          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="Yu Cheng" />
          <p class="site-author-name" itemprop="name">Yu Cheng</p>
          <p class="site-description motion-element" itemprop="description"></p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">6</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yu Cheng</span>
</div>

<!--<div class="powered-by">
 由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div> -->

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  

  

  

</body>
</html>
